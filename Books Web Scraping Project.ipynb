{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f63e5a-155a-4f2b-b3c2-4884cd6d3c47",
   "metadata": {},
   "source": [
    "#  Web Scraping Project on a Books Website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be77a572-c7ef-4a62-8ef8-d6a74e94303c",
   "metadata": {},
   "source": [
    "## Problem Statement:\n",
    "\n",
    "The objective of this web scraping project is to develop a robust and efficient tool capable of extracting key information from a book retailer’s website. The tool will systematically navigate through the website, accurately identifying and collecting data on book titles, prices, stock availability, and hyperlinks to individual book pages. This data will be meticulously parsed and structured to ensure consistency and readability.\n",
    "\n",
    "Upon successful extraction, the tool will then proceed to convert the gathered information into a well-organized and formatted CSV or Excel file. This file will serve as a comprehensive database, enabling easy access and analysis of the book inventory for various stakeholders, such as consumers, analysts, and other interested parties.\n",
    "\n",
    "The tool will be designed with a focus on adaptability to handle potential changes in the website’s layout and ensure compliance with web scraping best practices and legal guidelines. The end result will be a streamlined process that facilitates the monitoring of book-related data, supports price comparison, and aids in inventory management."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1b1533-906b-44e4-844c-842cac2ceec2",
   "metadata": {},
   "source": [
    "### Key Deliverables:\n",
    "- A web scraping tool that navigates and extracts data from a book website.\n",
    "- Extraction of book titles, prices, stock status, and URLs.\n",
    "- Conversion of the scraped data into a CSV or Excel file for easy analysis.\n",
    "- Adherence to ethical scraping guidelines and respect for the website's terms of service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db468fe2-5ee6-4326-ab4a-7d32f40e4bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee1ea32f-4ea5-421c-b010-260acfb535eb",
   "metadata": {},
   "source": [
    "## Preliminary: Importing libraries and defining known values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35c19829-daf6-41cd-b555-0998f0aeeb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b14850d-9aa2-4ef4-a6d6-36c1b6e152e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://books.toscrape.com/catalogue/page-1.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbcbced4-4473-4c31-9341-8af49fb7306b",
   "metadata": {},
   "outputs": [],
   "source": [
    " page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52ddcf54-760c-4d9c-a862-699d33257791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    All products | Books to Scrape - Sandbox\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0a8d47-2361-4fa3-803d-0367982465f8",
   "metadata": {},
   "source": [
    "the above result is correct because if we go to the any white space in the web page and rightclick, select **view page source**\n",
    "\n",
    "we will be pushed to a new tab and we'll see that the Title attribute = \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "48bcec4d-9f4d-4a92-b790-7767c5d2ce74",
   "metadata": {},
   "source": [
    "<head>\n",
    "[<title>]\n",
    "    All products | Books to Scrape - Sandbox\n",
    "</title>]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d61a7-5ca3-46c9-a674-6994bac1c053",
   "metadata": {},
   "source": [
    "We want to scrape to the end of the pages = 50\n",
    "assuming we do not know where the pages stop\n",
    "\n",
    "but we know that once the pages stop like if we go and paste 100 in the page number in the url(https://books.toscrape.com/catalogue/page-100.html) \n",
    "\n",
    "we will get **404 Not Found**\n",
    "and if we right click on the open space and select **view page source**, we will see this\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc419e06-be52-4cfe-8dd3-1d61745d9bcb",
   "metadata": {},
   "source": [
    "<head><title>404 Not Found</title></head>\n",
    "\n",
    "therefore we will know that the page ended where title == **404 Not Found**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06251a76-5a3d-49bd-8080-a36cf9813f44",
   "metadata": {},
   "source": [
    "## The Stages for the body of the code neccessary for effective web scraping\n",
    "#### Task 1\n",
    "**State the knowns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc05eeab-a46f-425b-977b-e76adb24b3f8",
   "metadata": {},
   "source": [
    "we have more than 1 page to scrape and each page contains more than 1 item to scrape therefore we need our url to be dynamic\n",
    "\n",
    "i.e change as the pages change on tha note we'll start with creating a dynamic **url**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbba2a1-144e-4b37-93cd-348b317bf0af",
   "metadata": {},
   "source": [
    "url = `\"https://books.toscrape.com/catalogue/page-1.html\"`\n",
    "\n",
    "To make this url dynamic , we'll replace the `page-1` with `page-current page` therefore we'll introduce the variable `current_page`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6adb5a7-6a89-42ae-9e0e-765697239bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_page = 1\n",
    "\n",
    "url = \"https://books.toscrape.com/catalogue/page-\"+str(current_page)+\".html\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text,\"html.parser\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57e9f4b-2146-4223-81dd-947eebee5706",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "**Identify/Introduce the Loops**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd4442c-f2ae-4b0b-b64d-98bc88debd27",
   "metadata": {},
   "source": [
    "1. We're scraping more than 1 page and in each page we have more than an Item to scrape\n",
    "2. We'll want the computer to stop at the end of the pages and we already know that  after the last valid page the rest invalid pages will show Title = `404 Not Found`\n",
    "3. The above fact will serve as the deciding factor for terminating the loop.\r",
    "enhancing our code we add\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4e3d86-a336-4961-a020-3bb998e1d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_page = 1\n",
    "\n",
    "url = \"https://books.toscrape.com/catalogue/page-\"+str(current_page)+\".html\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text,\"html.parser\")\n",
    "if soup.title.text == '404 Not Found':\n",
    "    proceed = False\n",
    "else:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd06472-5a2c-4d31-81e0-52382b55a036",
   "metadata": {},
   "source": [
    "We'll need to add `proceed - True` and also add `while(proceed == true):` since we've added `proceed = False` and observe its due **identations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505d433b-654f-48fe-8f94-fdd16190c5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_page = 1\n",
    "\n",
    "proceed = True\n",
    "while(proceed):    #this is same with while(proceed==True)\n",
    "    url = \"https://books.toscrape.com/catalogue/page-\"+str(current_page)+\".html\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,\"html.parser\")\n",
    "    if soup.title.text == '404 Not Found':\n",
    "        proceed = False\n",
    "    else:\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50b79b8-37ae-4860-9613-58da49f786df",
   "metadata": {},
   "source": [
    "### **Task 3**\n",
    "### *Extracting information*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9d0c8b-a47e-4bc6-a465-536b335258b0",
   "metadata": {},
   "source": [
    "1. Go to the web page and select the attribute that encompasses the whole object from where we'll be scraping using the command `find_all`\n",
    "2. determine items to scrape in our case\n",
    "    * `Title`\n",
    "    * `Link`\n",
    "    * `Price`\n",
    "    * `Stock`\n",
    "3. Create a dictionary `item` where this informations will be stored\n",
    "4. Note that to know what to scrape, you need to rightclick on the the item asnd then select `inspect` hover on the html and notice which line corresponds ur item of choice, use `book.find().atrrs[]` or `book.find(\"p\",class_=\"\") for p class\n",
    "5. Insert a counter that will move the iteration to the next page `current_page +=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44369469-5baa-4111-b5ae-d229b65ca5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_page = 1\n",
    "\n",
    "proceed = True\n",
    "while(proceed):    #this is same with while(proceed==True)\n",
    "    url = \"https://books.toscrape.com/catalogue/page-\"+str(current_page)+\".html\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,\"html.parser\")\n",
    "    if soup.title.text == '404 Not Found':\n",
    "        proceed = False\n",
    "    else:\n",
    "        all_books = soup.find_all(\"li\",class_=\"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
    "        for book in all_books:\n",
    "            item = {}\n",
    "            item['Title'] = book.find(\"img\").attrs[\"alt\"]\n",
    "            item['Link'] = book.find(\"a\").attrs[\"href\"]\n",
    "            item['Price'] = book.find('p',class_='price_color')\n",
    "            item['In_Stock'] = book.find('p',class_='instock availability')\n",
    "        \n",
    "        \n",
    "        current_page += 1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2f5a1-730a-47a2-a70f-0de2f8541a2c",
   "metadata": {},
   "source": [
    "### **Task 4**\n",
    "### *Validation*\n",
    "1. we'll check using the print statement to validate how well the scraping worked\n",
    "2. we'll introduce a terminator `proceed = False` to ensure the check is for just the current page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee8c5b-bb7a-41e4-a528-c52fee4b1abf",
   "metadata": {},
   "source": [
    "***1. Lets validate the `Title`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4337987c-dc7e-46f4-a4af-202d58bb0608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Light in the Attic\n",
      "Tipping the Velvet\n",
      "Soumission\n",
      "Sharp Objects\n",
      "Sapiens: A Brief History of Humankind\n",
      "The Requiem Red\n",
      "The Dirty Little Secrets of Getting Your Dream Job\n",
      "The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull\n",
      "The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics\n",
      "The Black Maria\n",
      "Starving Hearts (Triangular Trade Trilogy, #1)\n",
      "Shakespeare's Sonnets\n",
      "Set Me Free\n",
      "Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\n",
      "Rip it Up and Start Again\n",
      "Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991\n",
      "Olio\n",
      "Mesaerion: The Best Science Fiction Stories 1800-1849\n",
      "Libertarianism for Beginners\n",
      "It's Only the Himalayas\n"
     ]
    }
   ],
   "source": [
    "current_page = 1\n",
    "\n",
    "proceed = True\n",
    "while(proceed):    #this is same with while(proceed==True)\n",
    "    url = \"https://books.toscrape.com/catalogue/page-\"+str(current_page)+\".html\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,\"html.parser\")\n",
    "    if soup.title.text == '404 Not Found':\n",
    "        proceed = False\n",
    "    else:\n",
    "        all_books = soup.find_all(\"li\",class_=\"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
    "        for book in all_books:\n",
    "            item = {}\n",
    "            item['Title'] = book.find(\"img\").attrs[\"alt\"]\n",
    "            item['Link'] = book.find(\"a\").attrs[\"href\"]\n",
    "            item['Price'] = book.find('p',class_='price_color')\n",
    "            item['In_Stock'] = book.find('p',class_='instock availability')\n",
    "        \n",
    "            print(item['Title'])\n",
    "            proceed = False\n",
    "            \n",
    "        current_page += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18159d65-7287-44e1-84ee-a7ff30f3f635",
   "metadata": {},
   "source": [
    "**Good work!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f28272-b7d8-43b3-a49c-e73e771987e4",
   "metadata": {},
   "source": [
    "***2. Lets validate the `Link`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "281a0114-b123-4268-9097-025600bdc213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a-light-in-the-attic_1000/index.html\n",
      "tipping-the-velvet_999/index.html\n",
      "soumission_998/index.html\n",
      "sharp-objects_997/index.html\n",
      "sapiens-a-brief-history-of-humankind_996/index.html\n",
      "the-requiem-red_995/index.html\n",
      "the-dirty-little-secrets-of-getting-your-dream-job_994/index.html\n",
      "the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html\n",
      "the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html\n",
      "the-black-maria_991/index.html\n",
      "starving-hearts-triangular-trade-trilogy-1_990/index.html\n",
      "shakespeares-sonnets_989/index.html\n",
      "set-me-free_988/index.html\n",
      "scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\n",
      "rip-it-up-and-start-again_986/index.html\n",
      "our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html\n",
      "olio_984/index.html\n",
      "mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html\n",
      "libertarianism-for-beginners_982/index.html\n",
      "its-only-the-himalayas_981/index.html\n"
     ]
    }
   ],
   "source": [
    "current_page = 1\n",
    "\n",
    "proceed = True\n",
    "while(proceed):    #this is same with while(proceed==True)\n",
    "    url = \"https://books.toscrape.com/catalogue/page-\"+str(current_page)+\".html\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,\"html.parser\")\n",
    "    if soup.title.text == '404 Not Found':\n",
    "        proceed = False\n",
    "    else:\n",
    "        all_books = soup.find_all(\"li\",class_=\"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
    "        for book in all_books:\n",
    "            item = {}\n",
    "            item['Title'] = book.find(\"img\").attrs[\"alt\"]\n",
    "            item['Link'] = book.find(\"a\").attrs[\"href\"]\n",
    "            item['Price'] = book.find('p',class_='price_color')\n",
    "            item['In_Stock'] = book.find('p',class_='instock availability')\n",
    "        \n",
    "            print(item['Link'])\n",
    "            proceed = False\n",
    "            \n",
    "        current_page += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b7ae8d-0b61-49be-9b40-a3ac2070e9d9",
   "metadata": {},
   "source": [
    "**Good but didnt appear as an absolute link(relative Link)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52855b0b-9c6f-4e0f-9919-da76db8e5a24",
   "metadata": {},
   "source": [
    "The  item['Link'] shows relative values, to make it show absolute link value.\n",
    "\n",
    "to achieve this we go and copy `\"https://books.toscrape.com/catalogue/\"` and position it before the `book.find(\"a\")`\n",
    "\n",
    "to look like this `item['Link'] = \"https://books.toscrape.com/catalogue/page-\"+book.find(\"a\").attrs[\"href\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39f99e87-a366-4390-84ff-3a5ddb103872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\n",
      "https://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html\n",
      "https://books.toscrape.com/catalogue/soumission_998/index.html\n",
      "https://books.toscrape.com/catalogue/sharp-objects_997/index.html\n",
      "https://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996/index.html\n",
      "https://books.toscrape.com/catalogue/the-requiem-red_995/index.html\n",
      "https://books.toscrape.com/catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html\n",
      "https://books.toscrape.com/catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html\n",
      "https://books.toscrape.com/catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html\n",
      "https://books.toscrape.com/catalogue/the-black-maria_991/index.html\n",
      "https://books.toscrape.com/catalogue/starving-hearts-triangular-trade-trilogy-1_990/index.html\n",
      "https://books.toscrape.com/catalogue/shakespeares-sonnets_989/index.html\n",
      "https://books.toscrape.com/catalogue/set-me-free_988/index.html\n",
      "https://books.toscrape.com/catalogue/scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\n",
      "https://books.toscrape.com/catalogue/rip-it-up-and-start-again_986/index.html\n",
      "https://books.toscrape.com/catalogue/our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html\n",
      "https://books.toscrape.com/catalogue/olio_984/index.html\n",
      "https://books.toscrape.com/catalogue/mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html\n",
      "https://books.toscrape.com/catalogue/libertarianism-for-beginners_982/index.html\n",
      "https://books.toscrape.com/catalogue/its-only-the-himalayas_981/index.html\n"
     ]
    }
   ],
   "source": [
    "current_page = 1\n",
    "\n",
    "proceed = True\n",
    "while(proceed):    #this is same with while(proceed==True)\n",
    "    url = \"https://books.toscrape.com/catalogue/page-\"+str(current_page)+\".html\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,\"html.parser\")\n",
    "    if soup.title.text == '404 Not Found':\n",
    "        proceed = False\n",
    "    else:\n",
    "        all_books = soup.find_all(\"li\",class_=\"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
    "        for book in all_books:\n",
    "            item = {}\n",
    "            item['Title'] = book.find(\"img\").attrs[\"alt\"]\n",
    "            item['Link'] = \"https://books.toscrape.com/catalogue/\"+book.find(\"a\").attrs[\"href\"]\n",
    "            item['Price'] = book.find('p',class_='price_color')\n",
    "            item['In_Stock'] = book.find('p',class_='instock availability')\n",
    "        \n",
    "            print(item['Link'])\n",
    "            proceed = False\n",
    "            \n",
    "        current_page += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd333b2-0272-480f-877a-d9a27ab9463d",
   "metadata": {},
   "source": [
    "**Good work!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef276367-ea79-42eb-88a7-27863ed112f3",
   "metadata": {},
   "source": [
    "***3. Lets validate the `Price`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69a38bea-402c-419f-ad01-68a37dd8b796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"price_color\">Â£51.77</p>\n",
      "<p class=\"price_color\">Â£53.74</p>\n",
      "<p class=\"price_color\">Â£50.10</p>\n",
      "<p class=\"price_color\">Â£47.82</p>\n",
      "<p class=\"price_color\">Â£54.23</p>\n",
      "<p class=\"price_color\">Â£22.65</p>\n",
      "<p class=\"price_color\">Â£33.34</p>\n",
      "<p class=\"price_color\">Â£17.93</p>\n",
      "<p class=\"price_color\">Â£22.60</p>\n",
      "<p class=\"price_color\">Â£52.15</p>\n",
      "<p class=\"price_color\">Â£13.99</p>\n",
      "<p class=\"price_color\">Â£20.66</p>\n",
      "<p class=\"price_color\">Â£17.46</p>\n",
      "<p class=\"price_color\">Â£52.29</p>\n",
      "<p class=\"price_color\">Â£35.02</p>\n",
      "<p class=\"price_color\">Â£57.25</p>\n",
      "<p class=\"price_color\">Â£23.88</p>\n",
      "<p class=\"price_color\">Â£37.59</p>\n",
      "<p class=\"price_color\">Â£51.33</p>\n",
      "<p class=\"price_color\">Â£45.17</p>\n"
     ]
    }
   ],
   "source": [
    "current_page = 1\n",
    "\n",
    "proceed = True\n",
    "while(proceed):    #this is same with while(proceed==True)\n",
    "    url = \"https://books.toscrape.com/catalogue/page-\"+str(current_page)+\".html\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,\"html.parser\")\n",
    "    if soup.title.text == '404 Not Found':\n",
    "        proceed = False\n",
    "    else:\n",
    "        all_books = soup.find_all(\"li\",class_=\"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
    "        for book in all_books:\n",
    "            item = {}\n",
    "            item['Title'] = book.find(\"img\").attrs[\"alt\"]\n",
    "            item['Link'] = \"https://books.toscrape.com/catalogue/\"+book.find(\"a\").attrs[\"href\"]\n",
    "            item['Price'] = book.find('p',class_='price_color')\n",
    "            item['In_Stock'] = book.find('p',class_='instock availability')\n",
    "        \n",
    "            print(item['Price'])\n",
    "            proceed = False\n",
    "            \n",
    "        current_page += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a318593-f330-43f8-8be2-44475c30e396",
   "metadata": {},
   "source": [
    "**Good but we want only the number(figures) appearing**\n",
    "1. we add `.text` at the end of the `price` expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c74b3bf5-de6c-453a-82d8-06d37303863a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â£51.77\n",
      "Â£53.74\n",
      "Â£50.10\n",
      "Â£47.82\n",
      "Â£54.23\n",
      "Â£22.65\n",
      "Â£33.34\n",
      "Â£17.93\n",
      "Â£22.60\n",
      "Â£52.15\n",
      "Â£13.99\n",
      "Â£20.66\n",
      "Â£17.46\n",
      "Â£52.29\n",
      "Â£35.02\n",
      "Â£57.25\n",
      "Â£23.88\n",
      "Â£37.59\n",
      "Â£51.33\n",
      "Â£45.17\n"
     ]
    }
   ],
   "source": [
    "current_page = 1\n",
    "\n",
    "proceed = True\n",
    "while(proceed):    #this is same with while(proceed==True)\n",
    "    url = \"https://books.toscrape.com/catalogue/page-\"+str(current_page)+\".html\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,\"html.parser\")\n",
    "    if soup.title.text == '404 Not Found':\n",
    "        proceed = False\n",
    "    else:\n",
    "        all_books = soup.find_all(\"li\",class_=\"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
    "        for book in all_books:\n",
    "            item = {}\n",
    "            item['Title'] = book.find(\"img\").attrs[\"alt\"]\n",
    "            item['Link'] = \"https://books.toscrape.com/catalogue/\"+book.find(\"a\").attrs[\"href\"]\n",
    "            item['Price'] = book.find('p',class_='price_color').text\n",
    "            item['In_Stock'] = book.find('p',class_='instock availability')\n",
    "        \n",
    "            print(item['Price'])\n",
    "            proceed = False\n",
    "            \n",
    "        current_page += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc70d74-5f84-4b1c-915c-7e779d834e1e",
   "metadata": {},
   "source": [
    "**Good but we want only the number(figures) appearing**\n",
    "1. we'll use slicers to start after the 1st 2 index `[2:]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a20ffed-4e42-4e44-8be2-5742b0368d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.77\n",
      "53.74\n",
      "50.10\n",
      "47.82\n",
      "54.23\n",
      "22.65\n",
      "33.34\n",
      "17.93\n",
      "22.60\n",
      "52.15\n",
      "13.99\n",
      "20.66\n",
      "17.46\n",
      "52.29\n",
      "35.02\n",
      "57.25\n",
      "23.88\n",
      "37.59\n",
      "51.33\n",
      "45.17\n"
     ]
    }
   ],
   "source": [
    "current_page = 1\n",
    "\n",
    "proceed = True\n",
    "while(proceed):    #this is same with while(proceed==True)\n",
    "    url = \"https://books.toscrape.com/catalogue/page-\"+str(current_page)+\".html\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,\"html.parser\")\n",
    "    if soup.title.text == '404 Not Found':\n",
    "        proceed = False\n",
    "    else:\n",
    "        all_books = soup.find_all(\"li\",class_=\"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
    "        for book in all_books:\n",
    "            item = {}\n",
    "            item['Title'] = book.find(\"img\").attrs[\"alt\"]\n",
    "            item['Link'] = \"https://books.toscrape.com/catalogue/\"+book.find(\"a\").attrs[\"href\"]\n",
    "            item['Price'] = book.find('p',class_='price_color').text[2:]\n",
    "            item['In_Stock'] = book.find('p',class_='instock availability')\n",
    "        \n",
    "            print(item['Price'])\n",
    "            proceed = False\n",
    "            \n",
    "        current_page += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f9d06-09a8-45fa-85ac-aec9f37b6b8a",
   "metadata": {},
   "source": [
    "**Good work!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6d37c2-4be3-43f5-9a2c-395e3a5c55b2",
   "metadata": {},
   "source": [
    "***4. Lets validate the `in_stock`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06fb6eb5-66a0-41b9-92a9-195478c3623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "current_page = 1\n",
    "\n",
    "proceed = True\n",
    "while(proceed):    #this is same with while(proceed==True)\n",
    "    url = \"https://books.toscrape.com/catalogue/page-\"+str(current_page)+\".html\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,\"html.parser\")\n",
    "    if soup.title.text == '404 Not Found':\n",
    "        proceed = False\n",
    "    else:\n",
    "        all_books = soup.find_all(\"li\",class_=\"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
    "        for book in all_books:\n",
    "            item = {}\n",
    "            item['Title'] = book.find(\"img\").attrs[\"alt\"]\n",
    "            item['Link'] = \"https://books.toscrape.com/catalogue/\"+book.find(\"a\").attrs[\"href\"]\n",
    "            item['Price'] = book.find('p',class_='price_color').text[2:]\n",
    "            item['In_Stock'] = book.find('p',class_='instock availability')\n",
    "        \n",
    "            print(item['In_Stock'])\n",
    "            proceed = False\n",
    "            \n",
    "        current_page += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c228a40-2cd5-41fc-b8ee-bd637dcc59c9",
   "metadata": {},
   "source": [
    "**Observation** :\n",
    "1. We should always include `.text` at end of every `\"p\",class_=` to stop repeating introduction\n",
    "2. Include `strip()` to trim the wide spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23f8c7e6-9830-4d2e-b85a-a9e77462adda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stock\n",
      "In stock\n",
      "In stock\n",
      "In stock\n",
      "In stock\n",
      "In stock\n",
      "In stock\n",
      "In stock\n",
      "In stock\n",
      "In stock\n",
      "In stock\n",
      "In stock\n",
      "In stock\n",
      "In stock\n",
      "In stock\n",
      "In stock\n",
      "In stock\n",
      "In stock\n",
      "In stock\n",
      "In stock\n"
     ]
    }
   ],
   "source": [
    "current_page = 1\n",
    "\n",
    "proceed = True\n",
    "while(proceed):    #this is same with while(proceed==True)\n",
    "    url = \"https://books.toscrape.com/catalogue/page-\"+str(current_page)+\".html\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,\"html.parser\")\n",
    "    if soup.title.text == '404 Not Found':\n",
    "        proceed = False\n",
    "    else:\n",
    "        all_books = soup.find_all(\"li\",class_=\"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
    "        for book in all_books:\n",
    "            item = {}\n",
    "            item['Title'] = book.find(\"img\").attrs[\"alt\"]\n",
    "            item['Link'] = \"https://books.toscrape.com/catalogue/\"+book.find(\"a\").attrs[\"href\"]\n",
    "            item['Price'] = book.find('p',class_='price_color').text[2:]\n",
    "            item['In_Stock'] = book.find('p',class_='instock availability').text.strip()\n",
    "        \n",
    "            print(item['In_Stock'])\n",
    "            proceed = False\n",
    "            \n",
    "        current_page += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e126b5c-1c0e-41d7-81cd-ffebc9e0f0e8",
   "metadata": {},
   "source": [
    "**Good work!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307b065b-6bdc-4790-9897-220f25047bdb",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "**Loading**\n",
    "1. Remove the Terminator `proceed = True)` and the Print() statements\n",
    "2. To effectively load this data `item` into a CSV or Excel file we'll have to convert the dictionary `item` into a list `data`\n",
    "3. we'll introduce an empty list `data[]` and make sure that after every iteration for each item, they are stored in the data list\n",
    "4. Lets log the process so that while the computer scraping we'll see the current page\n",
    "5. Convert to dataframe `df` using the pandas library\n",
    "6. Load df to `CSV` and Load df to Excel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29d08d12-06ad-46b9-b395-da74d6c5cb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently Scraping Page :1\n",
      "currently Scraping Page :2\n",
      "currently Scraping Page :3\n",
      "currently Scraping Page :4\n",
      "currently Scraping Page :5\n",
      "currently Scraping Page :6\n",
      "currently Scraping Page :7\n",
      "currently Scraping Page :8\n",
      "currently Scraping Page :9\n",
      "currently Scraping Page :10\n",
      "currently Scraping Page :11\n",
      "currently Scraping Page :12\n",
      "currently Scraping Page :13\n",
      "currently Scraping Page :14\n",
      "currently Scraping Page :15\n",
      "currently Scraping Page :16\n",
      "currently Scraping Page :17\n",
      "currently Scraping Page :18\n",
      "currently Scraping Page :19\n",
      "currently Scraping Page :20\n",
      "currently Scraping Page :21\n",
      "currently Scraping Page :22\n",
      "currently Scraping Page :23\n",
      "currently Scraping Page :24\n",
      "currently Scraping Page :25\n",
      "currently Scraping Page :26\n",
      "currently Scraping Page :27\n",
      "currently Scraping Page :28\n",
      "currently Scraping Page :29\n",
      "currently Scraping Page :30\n",
      "currently Scraping Page :31\n",
      "currently Scraping Page :32\n",
      "currently Scraping Page :33\n",
      "currently Scraping Page :34\n",
      "currently Scraping Page :35\n",
      "currently Scraping Page :36\n",
      "currently Scraping Page :37\n",
      "currently Scraping Page :38\n",
      "currently Scraping Page :39\n",
      "currently Scraping Page :40\n",
      "currently Scraping Page :41\n",
      "currently Scraping Page :42\n",
      "currently Scraping Page :43\n",
      "currently Scraping Page :44\n",
      "currently Scraping Page :45\n",
      "currently Scraping Page :46\n",
      "currently Scraping Page :47\n",
      "currently Scraping Page :48\n",
      "currently Scraping Page :49\n",
      "currently Scraping Page :50\n",
      "currently Scraping Page :51\n"
     ]
    }
   ],
   "source": [
    "current_page = 1\n",
    "\n",
    "data = []\n",
    "proceed = True\n",
    "while(proceed):    #this is same with while(proceed==True)\n",
    "    print(\"currently Scraping Page :\"+str(current_page))\n",
    "    url = \"https://books.toscrape.com/catalogue/page-\"+str(current_page)+\".html\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,\"html.parser\")\n",
    "    if soup.title.text == '404 Not Found':\n",
    "        proceed = False\n",
    "    else:\n",
    "        all_books = soup.find_all(\"li\",class_=\"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
    "        for book in all_books:\n",
    "            item = {}\n",
    "            item['Title'] = book.find(\"img\").attrs[\"alt\"]\n",
    "            item['Link'] = \"https://books.toscrape.com/catalogue/\"+book.find(\"a\").attrs[\"href\"]\n",
    "            item['Price'] = book.find('p',class_='price_color').text[2:]\n",
    "            item['In_Stock'] = book.find('p',class_='instock availability').text.strip()\n",
    "        \n",
    "            data.append(item)\n",
    "         \n",
    "            \n",
    "        current_page += 1\n",
    "df = pd.DataFrame(data)      \n",
    "df.to_excel(\"books.xlsx\")    \n",
    "df.to_csv(\"books.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b1da03-bcf2-47d0-8740-244487479fba",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "**Load CSV**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aad518a4-b2f5-4b0e-8225-dd587b9a3774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>Price</th>\n",
       "      <th>In_Stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>https://books.toscrape.com/catalogue/a-light-i...</td>\n",
       "      <td>51.77</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>https://books.toscrape.com/catalogue/tipping-t...</td>\n",
       "      <td>53.74</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Soumission</td>\n",
       "      <td>https://books.toscrape.com/catalogue/soumissio...</td>\n",
       "      <td>50.10</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>https://books.toscrape.com/catalogue/sharp-obj...</td>\n",
       "      <td>47.82</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>https://books.toscrape.com/catalogue/sapiens-a...</td>\n",
       "      <td>54.23</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  Title  \\\n",
       "0           0                   A Light in the Attic   \n",
       "1           1                     Tipping the Velvet   \n",
       "2           2                             Soumission   \n",
       "3           3                          Sharp Objects   \n",
       "4           4  Sapiens: A Brief History of Humankind   \n",
       "\n",
       "                                                Link  Price  In_Stock  \n",
       "0  https://books.toscrape.com/catalogue/a-light-i...  51.77  In stock  \n",
       "1  https://books.toscrape.com/catalogue/tipping-t...  53.74  In stock  \n",
       "2  https://books.toscrape.com/catalogue/soumissio...  50.10  In stock  \n",
       "3  https://books.toscrape.com/catalogue/sharp-obj...  47.82  In stock  \n",
       "4  https://books.toscrape.com/catalogue/sapiens-a...  54.23  In stock  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"books.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1923f9ec-8cb5-4a25-a2df-0ccb629e1d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff68023d-012c-46f1-916e-f34e216f1fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd883a2-f359-4877-8bdc-533e9bde05d8",
   "metadata": {},
   "source": [
    "## Conclusion:\r\n",
    "\r\n",
    "The web scraping project aimed at extracting critical information from a book retailer’s website has been successfully completed. The tool developed for this purpose has proven to be highly effective in navigating the website, identifying, and retrieving data on book titles, prices, stock levels, and URLs. The accuracy and reliability of the data collected are commendable, reflecting the tool’s robustness against potential challenges such as website layout changes.\r\n",
    "\r\n",
    "The conversion process, which reformats the scraped data into a CSV or Excel file, has been executed flawlessly, resulting in a well-structured and comprehensive dataset. This dataset not only enhances the accessibility and usability of the information but also opens avenues for in-depth analysis and strategic decision-making.\r\n",
    "\r\n",
    "This project has demonstrated the power of web scraping in transforming raw website data into valuable insights. The success of this endeavor underscores the potential for similar tools to revolutionize data collection and analysis across various domains. As we conclude, we celebrate the seamless integration of technology and data management that this project represents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc88406e-7edd-44c3-b9d7-f13f1fe08d01",
   "metadata": {},
   "source": [
    "### Key Achievements:\n",
    "- Successful extraction of book-related data from a web source.\n",
    "- Accurate parsing and structuring of information into a user-friendly format.\n",
    "- Creation of a versatile dataset for analysis and inventory management.\n",
    "- Demonstration of ethical web scraping practices and compliance with legal standards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634fae9-75f8-466a-9328-693f8fd3baf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
